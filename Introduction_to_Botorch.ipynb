{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Introduction_to_Botorch.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_wEfJ_FcN9c",
        "colab_type": "text"
      },
      "source": [
        "# BoTorch Tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu2gzuRGcN9d",
        "colab_type": "text"
      },
      "source": [
        "The following information is summarised from the main BoTorch website.\n",
        "https://botorch.org/docs/introduction.html\n",
        "\n",
        "I have decided to summarise it to extract the core information from the documents to get started.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzWdvPY7cN9e",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to BoTorch\n",
        "\n",
        "BoTorch is a library for Bayesian Optimisation research built on top of PyTorch. \n",
        "\n",
        "Bayesian Optimisation (BayesOpt) is an established technique for sequential optimisation of costly-to-evaluate black box functions. It can be applied to a wide variety of problems, including hyperparameter optimisation for machine learning algorithms, A/B testing, as well as many scientific and engineering problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj26AxhOcN9f",
        "colab_type": "text"
      },
      "source": [
        "## Why Botorch?\n",
        "\n",
        "1. Improved Developer Efficiency\n",
        "--> Modular and easily extensible interface for composing Bayesian Optimisation primitives (include probabilitic mdels, acquisition functions and optimisers).\n",
        "--> Utilise quasi-Monte-Carlo acquisition functions\n",
        "\n",
        "2. State-of-the-art Modelling\n",
        "--> Provide support for state-of-the-art probabilisitc models in GPyTorch (Library for efficient, scalable Gaussian Process implemented in PyTorch).\n",
        "--> Features include multi-task GPs, deep kernel learning, deep GPs, and approximate inference\n",
        "\n",
        "3. Harnessing the features of PyTorch\n",
        "--> Auto-differentiation, GPU implementations and dynamic computation graph \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DRNZGUccN9f",
        "colab_type": "text"
      },
      "source": [
        "# Simple Programme to get started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O0VRs_g9cN9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ===============\n",
        "# Install BoTorch\n",
        "# ===============\n",
        "\n",
        "# Via conda\n",
        "# conda install botorch -c pytorch -c gpytorch\n",
        "\n",
        "# Via pip\n",
        "!pip install botorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FMupZBePcN9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ===============\n",
        "# Fitting a Model\n",
        "# ===============\n",
        "\n",
        "import torch\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.fit import fit_gpytorch_model\n",
        "from botorch.utils import standardize\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "\n",
        "\n",
        "# Create training set\n",
        "train_X = torch.rand(10,2)  # Create random matrix 10 rows x 2 columns\n",
        "print(\"Training X \\n\\f\\n\", train_X)\n",
        "Y = 1 - torch.norm(train_X-0.5,dim=-1,keepdim=True) # Generate Y\n",
        "print(\"\\nY\\n\\f\\n\", Y)\n",
        "Y = Y + 0.1*torch.randn_like(Y)  # Add some noise\n",
        "print(\"\\nY with noise\\n\\f\\n\", Y)\n",
        "train_Y = standardize(Y) # Stadardisation of Y for training\n",
        "\n",
        "gp = SingleTaskGP(train_X,train_Y)\n",
        "mll = ExactMarginalLogLikelihood(gp.likelihood,gp)\n",
        "fit_gpytorch_model(mll)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "W-iR3Z6LcN9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}